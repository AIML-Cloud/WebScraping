{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYd2uhN35c7f"
   },
   "source": [
    "# Regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "82NirFAl5c7i"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Wk4GLrX55c7j"
   },
   "outputs": [],
   "source": [
    "text = 'Around 2500 patients are taking part in clinical trails #Coronavirus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='Sachin is an all rounder in cricket world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sachin', 'is', 'an', 'all', 'rounder', 'in', 'cricket', 'world']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[a-zA-Z]+',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1IJ-bWn75c7j",
    "outputId": "16bb4049-85ee-44f3-dd22-038b538eb81c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 2500 patients are taking part in clinical trails #Coronavirus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['round',\n",
       " 'patients',\n",
       " 'are',\n",
       " 'taking',\n",
       " 'part',\n",
       " 'in',\n",
       " 'clinical',\n",
       " 'trails',\n",
       " 'oronavirus']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text)\n",
    "re.findall('[a-z]+', text) # Find all sequency of lower case characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FcZoVnLd5c7o",
    "outputId": "05ee301f-8bf2-4fdf-ccb7-724f69f7a3d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 2500 patients are taking part in clinical trails #Coronavirus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Around',\n",
       " 'patients',\n",
       " 'are',\n",
       " 'taking',\n",
       " 'part',\n",
       " 'in',\n",
       " 'clinical',\n",
       " 'trails',\n",
       " 'Coronavirus']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text)\n",
    "re.findall('[a-zA-Z]+', text) # Find all sequency of lower & upper case characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXHcVPGe5c7p"
   },
   "source": [
    " Extended Regular Expressions:\n",
    " \n",
    "     \\d -> Any digit, equivalent to [0-9]\n",
    "     \\D -> Any non-digit, equivalent to [^0-9]\n",
    "    \\w -> Any alphanumeric, equivalent to [a-zA-Z0-9_]\n",
    "    \\W -> Non-alphanumeric, equivalent to [^a-zA-Z0-9_]\n",
    "    \\s -> Any whitespace character\n",
    "    \\S -> Any nonwhitespace character\n",
    "    \n",
    "    () -> Scoping for extraction\n",
    "    {} -> Frequency for extraction\n",
    "    ? -> Make a pattern non greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ze2MwT5-5c7q",
    "outputId": "ea96739d-01aa-4914-9ff9-0f2cdc94a123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 2500 patients are taking part in clinical trails #Coronavirus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Around',\n",
       " '2500',\n",
       " 'patients',\n",
       " 'are',\n",
       " 'taking',\n",
       " 'part',\n",
       " 'in',\n",
       " 'clinical',\n",
       " 'trails',\n",
       " 'Coronavirus']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text)\n",
    "re.findall('\\w+', text) # Find all sequency of word characters[a-zA-Z0-9_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "R2RoIt9X5c7r"
   },
   "outputs": [],
   "source": [
    "text = \"The film Titanic was released in year 98 and was a hit till the year 2000 \\n5000 was the cost of the mobile\\ni baragined it to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "fljuhVJ15c7r",
    "outputId": "86f9d334-046c-46fe-e662-3b34aed4249c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The film Titanic was released in year 98 and was a hit till the year 2000 \n",
      "5000 was the cost of the mobile\n",
      "i baragined it to\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "mFNFtzWJ5c7s",
    "outputId": "b64be208-c5e0-4174-a1aa-5a62b0c7efa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['98', '2000']\n",
      "['5000']\n"
     ]
    }
   ],
   "source": [
    "for line in text.split(\"\\n\"):\n",
    "    patterns = re.findall(\"\\d+\",line)\n",
    "    if len(patterns)>0:\n",
    "        print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "QFXICW7V5c7s",
    "outputId": "83b34c98-52c5-4bec-b6cf-08febaafb597"
   },
   "outputs": [],
   "source": [
    "for line in text.split(\"\\n\"):\n",
    "    line = line.strip()\n",
    "    find = re.findall(\"\\d{4}\\$\",line)\n",
    "    if len(find)>0: \n",
    "        print(find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "Nsgr-dnk5c7t"
   },
   "outputs": [],
   "source": [
    "text = 'A message from csev@umich.edu to cwen@iupui.edu about meeting @2PM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "TTHQR7xD5c7t",
    "outputId": "270a047c-6ec9-474b-bad4-62c61fc2e02c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csev@umich.edu', 'cwen@iupui.edu']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\S+@\\S+\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lmFFIb4m5c7u",
    "outputId": "e6e660dd-6a7b-4fc1-fb7c-f7d0291fbae5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' @2PM']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\s+@\\S+\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KXbhKej75c7v",
    "outputId": "8df1e0ab-ab03-4f4b-8dd2-6e947a535614"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['umich.edu', 'iupui.edu']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\S+@(\\S+)\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cS3iCfFo5c7v",
    "outputId": "d3f28f1b-d722-45dc-ad3c-f431c2f7ac68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csev', 'cwen']"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"(\\S+)@\\S+\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC5Dc_ha5c7w"
   },
   "source": [
    "#### Cleaning text using re.sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "_9VCB3AG5c7w"
   },
   "outputs": [],
   "source": [
    "text = 'Around 2,500 patients are taking part in ** clinical trails #Coronavirus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "sGt17sZ-5c7x",
    "outputId": "f2c79049-83a9-4e4a-c85d-e9eca257ce3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 2,500 patients are taking part in ** clinical trails #Coronavirus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Around2500patientsaretakingpartinclinicaltrailsCoronavirus'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text)\n",
    "re.sub('[^\\w+]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "9IS5w10T5c7x",
    "outputId": "0ec873b6-262c-4f17-eda7-2a8d4e7cc849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 2,500 patients are taking part in ** clinical trails #Coronavirus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'this is my string    remove'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(text)\n",
    "ss ='this is my string & && (* remove'\n",
    "re.sub('[^\\w+\\s]', '', ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "f4dOcGUl5c7y"
   },
   "outputs": [],
   "source": [
    "text = \"film ABC  @ was ? produced %  in , year $ 1994  .  'by'   Mr_X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "9dzlDSSB5c7y",
    "outputId": "8cd78de6-f491-4f0a-8d04-bb8c0dfbae5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'film ABC   was  produced   in  year  1994    by   MrX'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing special charecters with nothing\n",
    "result1 = re.sub(\"[,@'?.$%_]\", \"\", text)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "nWqSTskk5c78",
    "outputId": "5117dfed-8532-472e-ef01-848773da68e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'film ABC   was  produced   in  year  1994    by   MrX'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing special charecters(non Alpha numeric and Space) with nothing\n",
    "result1 = re.sub(\"[^a-zA-Z0-9 ]\",\"\",text)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "owNa3vcG5c79",
    "outputId": "67fff07f-d2ac-4593-8245-1c18ce1ebf08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'film ABC   was  produced   in  year  1994    by   Mr_X'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\W -> Alphanumeric with underscores\n",
    "#\\s -> Space\n",
    "result1 = re.sub(\"[^\\w\\s]\",\"\",text)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umsK--xL5c79",
    "outputId": "e983b3dd-1ef0-4021-b601-10d47b1d94e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'film ABC was produced in year 1994 by Mr_X'"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing multiple spaces with a single space\n",
    "result = re.sub(\"\\s+\", \" \", result1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR8EHAgR5c7-"
   },
   "source": [
    "### Extracting text from HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "PioXi0yY5c7-"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"<div>\n",
    "<h1> H2O</h1>\n",
    "<p> AutoML</p>\n",
    "<a href=\"https://www.amazon.ai/products/h2o-driverless-ai/\"> Driverless AI</a>\n",
    "</div>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "2-qO-qgF5c7-",
    "outputId": "3e8029a8-6303-4929-c0e1-6c01346b3b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "<h1> H2O</h1>\n",
      "<p> AutoML</p>\n",
      "<a href=\"https://www.amazon.ai/products/h2o-driverless-ai/\"> Driverless AI</a>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cw_QUz8s5c7-"
   },
   "source": [
    "To Extract Text Between the HTML tages we need to remove all the text between < and >\n",
    "i.e remove  Zero or more occourrence of any chatecter between < and >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "STgRuGZZ5c7_",
    "outputId": "ac035d40-38cc-4c94-c51e-53060db8ef5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " H2O\n",
      " AutoML\n",
      " Driverless AI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(re.sub('<.*?>',\"\",text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJh6IdZx5c7_"
   },
   "outputs": [],
   "source": [
    "#.* and + are greedy - it matches everything including the closing angular bracket >\n",
    "# .* and .+ should stop matching a pattern as soon as it encounters the closing angular bracket\n",
    "# use a \"?\" along with .* and .+ to make it non greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OT0s38Kn5c7_",
    "outputId": "9c487c1b-e7b1-4cad-d260-2a5dcb87897b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " H2O\n",
      " AutoML\n",
      " Driverless AI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(re.sub('<.*?>',\"\",text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtVACSax5c8A"
   },
   "source": [
    "## Extracting hashtags from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lONEdjjn5c8A",
    "outputId": "35dd9ea8-ece1-451d-e325-645f5685c0b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 2,500 patients are taking part in clinical trails #Coronavirus\n",
      "['#Coronavirus']\n"
     ]
    }
   ],
   "source": [
    "text = 'Around 2,500 patients are taking part in clinical trails #Coronavirus'\n",
    "print(text)\n",
    "print(re.findall('#\\w+', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uA-fwcm-5c8A",
    "outputId": "36a7c268-bdbf-4aa7-d20d-f44402c25190"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-17 03:27:56</td>\n",
       "      <td>en</td>\n",
       "      <td>123212.0</td>\n",
       "      <td>18568.0</td>\n",
       "      <td>96% Approval Rating in the Republican Party. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-17 02:45:33</td>\n",
       "      <td>und</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7942.0</td>\n",
       "      <td>RT @TONYxTWO: @thejtlewis @JoeBiden https://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-17 02:38:20</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23815.0</td>\n",
       "      <td>RT @thejtlewis: “Trump isn’t going to accept t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-17 02:37:01</td>\n",
       "      <td>en</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6781.0</td>\n",
       "      <td>RT @thejtlewis: With the utmost respect, I tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-17 02:31:11</td>\n",
       "      <td>en</td>\n",
       "      <td>56840.0</td>\n",
       "      <td>14231.0</td>\n",
       "      <td>A GREAT woman. Her son is looking down from he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at language     likes  retweets  \\\n",
       "0  2020-06-17 03:27:56       en  123212.0   18568.0   \n",
       "1  2020-06-17 02:45:33      und       0.0    7942.0   \n",
       "2  2020-06-17 02:38:20       en       0.0   23815.0   \n",
       "3  2020-06-17 02:37:01       en       0.0    6781.0   \n",
       "4  2020-06-17 02:31:11       en   56840.0   14231.0   \n",
       "\n",
       "                                                text  \n",
       "0  96% Approval Rating in the Republican Party. T...  \n",
       "1  RT @TONYxTWO: @thejtlewis @JoeBiden https://t....  \n",
       "2  RT @thejtlewis: “Trump isn’t going to accept t...  \n",
       "3  RT @thejtlewis: With the utmost respect, I tha...  \n",
       "4  A GREAT woman. Her son is looking down from he...  "
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('C:/Users/Raghavendra N/OneDrive/Official/Datasets/tweets_donald_trump.csv')\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I3ibrHu5c8B"
   },
   "source": [
    "Obtain the frequency of each of the hashtags\n",
    "\n",
    "- Step1: Extract all the hash tags and store them in a list\n",
    "- Step2: Compute the frequency of each of the hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPOHB-jP5c8M"
   },
   "source": [
    "## Cleaning salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HT-q1qqx5c8N",
    "outputId": "dbb2996c-cadc-4d3b-fc16-ba7267ed4ac4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>experience</th>\n",
       "      <th>skills</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>description</th>\n",
       "      <th>posted_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>2-4 yrs</td>\n",
       "      <td>Algorithms, Machine Learning, Python, Java, Da...</td>\n",
       "      <td>Netcore Solutions Pvt Ltd</td>\n",
       "      <td>2,00,000 - 7,00,000 P.A.</td>\n",
       "      <td>At least 2 year of experience in data engineer...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyst / Sr. Analyst (data Science)</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>5-8 yrs</td>\n",
       "      <td>predictive modeling, predictive analytics, mac...</td>\n",
       "      <td>Cvent India Pvt. Ltd.</td>\n",
       "      <td>5,00,000 - 10,00,000 P.A.</td>\n",
       "      <td>Strong experience on providing predictive mode...</td>\n",
       "      <td>Today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ETL Lead &amp; Data Science</td>\n",
       "      <td>Chennai, Bengaluru, Mumbai, Pune, Noida</td>\n",
       "      <td>7-10 yrs</td>\n",
       "      <td>SQL, Data Analysis, Text Mining, SAS, R, Stati...</td>\n",
       "      <td>COMPUTER POWER GROUP PRIVATE LIMITED</td>\n",
       "      <td>10,00,000 - 15,00,000 P.A.</td>\n",
       "      <td>Industry experience in building and operationa...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Specialist - Data Science</td>\n",
       "      <td>Delhi NCR, Bengaluru, Gurgaon</td>\n",
       "      <td>7-12 yrs</td>\n",
       "      <td>Specialist - Data Science, Data Science, data ...</td>\n",
       "      <td>Brainsearch Consulting Pvt Ltd.Â</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>- Experience with one or more data science pro...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Group Manager - Data Science - Python/nlp</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>6-11 yrs</td>\n",
       "      <td>machine learning, text mining, r, nlp, data sc...</td>\n",
       "      <td>Staffio HR</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>- This is a Team management role  - Skill set ...</td>\n",
       "      <td>1 day ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  \\\n",
       "0                               Data Science   \n",
       "1       Analyst / Sr. Analyst (data Science)   \n",
       "2                    ETL Lead & Data Science   \n",
       "3                  Specialist - Data Science   \n",
       "4  Group Manager - Data Science - Python/nlp   \n",
       "\n",
       "                                  location experience  \\\n",
       "0                                   Mumbai    2-4 yrs   \n",
       "1                                  Gurgaon    5-8 yrs   \n",
       "2  Chennai, Bengaluru, Mumbai, Pune, Noida   7-10 yrs   \n",
       "3            Delhi NCR, Bengaluru, Gurgaon   7-12 yrs   \n",
       "4                                Bengaluru   6-11 yrs   \n",
       "\n",
       "                                              skills  \\\n",
       "0  Algorithms, Machine Learning, Python, Java, Da...   \n",
       "1  predictive modeling, predictive analytics, mac...   \n",
       "2  SQL, Data Analysis, Text Mining, SAS, R, Stati...   \n",
       "3  Specialist - Data Science, Data Science, data ...   \n",
       "4  machine learning, text mining, r, nlp, data sc...   \n",
       "\n",
       "                                company                            salary  \\\n",
       "0             Netcore Solutions Pvt Ltd        2,00,000 - 7,00,000 P.A.     \n",
       "1                 Cvent India Pvt. Ltd.       5,00,000 - 10,00,000 P.A.     \n",
       "2  COMPUTER POWER GROUP PRIVATE LIMITED      10,00,000 - 15,00,000 P.A.     \n",
       "3     Brainsearch Consulting Pvt Ltd.Â                     Not disclosed    \n",
       "4                            Staffio HR                    Not disclosed    \n",
       "\n",
       "                                         description posted_date  \n",
       "0  At least 2 year of experience in data engineer...   1 day ago  \n",
       "1  Strong experience on providing predictive mode...       Today  \n",
       "2  Industry experience in building and operationa...   1 day ago  \n",
       "3  - Experience with one or more data science pro...   1 day ago  \n",
       "4  - This is a Team management role  - Skill set ...   1 day ago  "
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.read_csv('C:/Users/Raghavendra N/OneDrive/Official/Datasets/datascience_jobs.csv')\n",
    "jobs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eJDMARm5c8N"
   },
   "outputs": [],
   "source": [
    "# Task : From the salary column extract the minimum and maximum salary, NA if unable to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'66.6'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings =' 66 .6 anil'\n",
    "re.sub('[^\\d+\\.]','',strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "3.Regular expressions_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
